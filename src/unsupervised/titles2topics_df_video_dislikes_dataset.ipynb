{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T21:14:57.225258700Z",
     "start_time": "2023-06-05T21:14:57.090746600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1108)>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import numpy as np\n",
    "import gensim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from statistics import mean\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#venv m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18712\n",
      "18710\n"
     ]
    }
   ],
   "source": [
    "path = '../data_cleaning/data/youtube_dislike_dataset.csv' #raw download\n",
    "clean_transcripts = pd.read_csv(path)\n",
    "clean_transcripts.head(1)\n",
    "#splitting the dislikes dataframe by the median \n",
    "clean_transcripts['dislikes'].median()\n",
    "below_median = clean_transcripts[clean_transcripts['dislikes'] < 796]\n",
    "above_median = clean_transcripts[clean_transcripts['dislikes'] >= 796]\n",
    "print(len(above_median))\n",
    "print(len(below_median))\n",
    "#Create Final Text Column for Machine Learning and Remove Stop Words\n",
    "below_median[\"all_text\"] = below_median[\"title\"] + below_median[\"description\"]\n",
    "above_median[\"all_text\"] = above_median[\"title\"] + above_median[\"description\"]\n",
    "stop = stopwords.words('english')\n",
    "below_median['all_text'] = below_median['all_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "above_median['all_text'] = above_median['all_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "below_median['title'] = below_median['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "above_median['title'] = above_median['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T21:14:58.245740100Z",
     "start_time": "2023-06-05T21:14:58.242573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18710\n"
     ]
    }
   ],
   "source": [
    "clean_transcripts_list = below_median['title'].tolist()\n",
    "documents_train = clean_transcripts_list\n",
    "print(len(documents_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T21:15:33.952488500Z",
     "start_time": "2023-06-05T21:14:58.812326300Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_lda(n_topics,documents_train):\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    tfidf_documents = tfidf_vectorizer.fit_transform(documents_train)\n",
    "    tf_vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "    tf_documents = tf_vectorizer.fit_transform(documents_train)\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names_out()\n",
    "\n",
    "    # This cell will take a couple of minutes to run...\n",
    "    lda = LatentDirichletAllocation(n_components=n_topics, random_state=0)\n",
    "    lda.fit(tf_documents)\n",
    "    topic_models = lda.components_\n",
    "    num_top_words = 8\n",
    "    return lda, tf_feature_names, num_top_words\n",
    "    #display_topics(lda, tf_feature_names, num_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topic_to_terms = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        term_list = [\n",
    "            feature_names[i] for i in topic.argsort()[: -no_top_words - 1 : -1]\n",
    "        ]\n",
    "        #print(\"topic %d:\" % (topic_idx), term_list)\n",
    "        topic_to_terms[topic_idx] = term_list\n",
    "    return topic_to_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = '../../../word2vec/GoogleNews-vectors-negative300.bin'\n",
    "Word2VecModel = KeyedVectors.load_word2vec_format(pretrained_path, binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.40483522, 0.31330317, 0.2883513)\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/code/nkitgupta/text-representations\n",
    "def topical_coherence(items, w2vmodel):\n",
    "\n",
    "    result = []\n",
    "    for item in items:\n",
    "        try:\n",
    "            if w2vmodel==Word2VecModel:\n",
    "                result.append(w2vmodel[item[0]])\n",
    "            elif w2vmodel==glove_embeddings:\n",
    "                result.append(w2vmodel[item[0]])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    if len(result) == 0:\n",
    "        return 0\n",
    "\n",
    "    matrix_sim = cosine_similarity(result)\n",
    "    np.fill_diagonal(matrix_sim, 0)\n",
    "    return np.mean(matrix_sim)\n",
    "\n",
    "def answer_coherence_a(w2vmodel):\n",
    "    a = topical_coherence(['train', 'car', 'bicycle', 'bus', 'vehicle', 'transport'], w2vmodel)\n",
    "    b = topical_coherence(['scsi', 'drive', 'computer', 'storage', 'megabyte'], w2vmodel)\n",
    "    c = topical_coherence(['introduction', 'pickle', 'guard', 'red', 'valiant'], w2vmodel)\n",
    "\n",
    "    return a, b, c\n",
    "print(\"These values reveal that good coherences are roughly above 0.3 \")\n",
    "print(answer_coherence_a(w2vmodel=Word2VecModel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_coherence_per_lda(test_found_topics, min_coherence=0.33):\n",
    "    coherence_per_lda = []\n",
    "    remaining_topics = []\n",
    "    num_removed_topics = 0\n",
    "    for key in test_found_topics.keys():\n",
    "        terms = test_found_topics[key]\n",
    "        val = topical_coherence(terms, w2vmodel=Word2VecModel)\n",
    "        if val>min_coherence:\n",
    "            coherence_per_lda.append(val)\n",
    "            remaining_topics.append(terms)\n",
    "        else:\n",
    "            num_removed_topics += 1\n",
    "    return mean(coherence_per_lda),remaining_topics,num_removed_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_lda_per_df(documents_train):\n",
    "    max_topics = None\n",
    "    max_lda = None\n",
    "    max_tf_feature_names = None\n",
    "    max_num_top_words = None\n",
    "    max_coherence = 0\n",
    "    best_topics = None\n",
    "    final_num_removed_topics = None\n",
    "    results = []\n",
    "    for i in tqdm(range(5, 15, 1)):\n",
    "        lda, tf_feature_names, num_top_words = compute_lda(i,documents_train)\n",
    "        test_found_topics = display_topics(lda, tf_feature_names, num_top_words)\n",
    "        coherence, remaining_topics,num_removed_topcs = mean_coherence_per_lda(test_found_topics)\n",
    "        results.append(coherence)\n",
    "        if coherence>max_coherence:\n",
    "            max_coherence = coherence\n",
    "            max_lda = lda\n",
    "            max_tf_feature_names = tf_feature_names\n",
    "            max_num_top_words = num_top_words\n",
    "            max_topics = i\n",
    "            best_topics = test_found_topics\n",
    "            final_num_removed_topics = num_removed_topcs\n",
    "    print(f\"best number topics: {max_topics}\")\n",
    "    print(results)\n",
    "    print(max_coherence)\n",
    "    print(\"The values for the best average coherence model are\")\n",
    "    print(display_topics(max_lda, max_tf_feature_names, num_top_words))\n",
    "    print(f\"Number of final topics removed: {final_num_removed_topics}\")\n",
    "    return remaining_topics, max_topics\n",
    "    #19 was best  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:37<00:00, 39.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best number topics: 14\n",
      "[0.36841208, 0.35977232, 0.35831177, 0.35342705, 0.36817968, 0.36395422, 0.3481807, 0.37460297, 0.3514898, 0.38780206]\n",
      "0.38780206\n",
      "The values for the best average coherence model are\n",
      "{0: ['vs', 'ufc', 'fifa', 'team', 'fight', 'pregnant', 'celtic', '22'], 1: ['nba', 'tv', '2021', 'episode', 'lakers', 'game', 'hermitcraft', 'ep'], 2: ['scenes', '2020', 'minecraft', 'live', 'chunkz', 'watch', 'day', 'fans'], 3: ['fortnite', '2021', 'la', 'en', 'new', 'episode', 'les', 'vlog'], 4: ['trailer', 'official', 'season', 'ft', 'little', '000', 'tour', 'announcement'], 5: ['video', 'official', 'music', 'feat', 'audio', 'ft', 'ep', 'lil'], 6: ['man', 'news', 'utd', 'transfer', 'united', 'goldbridge', 'manchester', 'reaction'], 7: ['highlights', 'league', 'vs', 'premier', 'city', 'united', 'arsenal', 'chelsea'], 8: ['2020', 'highlights', 'vs', 'world', 'cup', 'week', 'game', 'nfl'], 9: ['new', 'update', 'car', '2021', 'results', 'national', 'draw', 'lottery'], 10: ['live', '2021', 'quiz', 'virtual', 'pub', 'la', 'date', 'day'], 11: ['2021', 'highlights', '21', 'vs', '2020', 'game', 'round', 'nhl'], 12: ['house', 'new', 'tour', 'year', 'van', 'home', 'moving', 'tom'], 13: ['best', 'day', 'life', '2020', 'baby', 'reveal', 'nba', 'build']}\n",
      "Number of final topics removed: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "documents_train_below = below_median[\"title\"]\n",
    "remaining_topics_below, max_topics_below = best_lda_per_df(documents_train_below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:47<00:00, 34.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best number topics: 14\n",
      "[0.37262762, 0.3813132, 0.37289613, 0.36515358, 0.371236, 0.36844745, 0.38009697, 0.35895538, 0.36470556, 0.38535935]\n",
      "0.38535935\n",
      "The values for the best average coherence model are\n",
      "{0: ['vs', 'highlights', '2020', 'week', 'news', '2021', 'nfl', 'super'], 1: ['vs', 'iphone', 'sidemen', '12', 'tv', 'pro', 'la', '19'], 2: ['minecraft', '100', 'days', 'vs', '24', 'man', 'dream', 'paul'], 3: ['2021', 'ep', 'highlights', 'final', 'ka', 'episode', 'league', 'taarak'], 4: ['000', 'en', 'le', 'les', 'challenge', 'wins', 'la', 'ft'], 5: ['shorts', 'fortnite', 'tiktok', 'season', 'vs', 'new', 'challenge', 'hacks'], 6: ['trailer', 'official', 'theory', 'film', 'reveal', 'food', 'teaser', 'don'], 7: ['night', 'friday', 'funkin', 'mod', 'live', 'hot', 'tour', 'animation'], 8: ['video', 'official', 'music', 'ft', 'feat', 'lil', 'audio', 'oficial'], 9: ['game', '2021', '2020', 'highlights', 'bts', 'life', 'squid', 'clip'], 10: ['minecraft', 'new', 'star', 'update', 'day', 'tik', 'fortnite', '2021'], 11: ['race', 'drag', 'stop', 'world', 'brawl', 'ep', 'vs', 'tesla'], 12: ['mv', 'teaser', '2020', 'bad', 'boss', 'try', '2021', 'movie'], 13: ['free', 'got', 'people', 'season', 'war', 'unboxing', 'snl', 'cold']}\n",
      "Number of final topics removed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "documents_train_above = above_median[\"title\"]\n",
    "remaining_topics_above, max_topics_above= best_lda_per_df(documents_train_above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_findings_table(remaining_topics):\n",
    "    df = pd.DataFrame()\n",
    "    # Iterate over each inner list\n",
    "    for i, inner_list in enumerate(remaining_topics):\n",
    "        # Create a new column with column name as 'Column_i'\n",
    "        df['Topic{}'.format(i)] = inner_list\n",
    "    # Display the DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Topic7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trailer</td>\n",
       "      <td>man</td>\n",
       "      <td>highlights</td>\n",
       "      <td>2020</td>\n",
       "      <td>new</td>\n",
       "      <td>live</td>\n",
       "      <td>house</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>official</td>\n",
       "      <td>news</td>\n",
       "      <td>league</td>\n",
       "      <td>highlights</td>\n",
       "      <td>update</td>\n",
       "      <td>2021</td>\n",
       "      <td>new</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>season</td>\n",
       "      <td>utd</td>\n",
       "      <td>vs</td>\n",
       "      <td>vs</td>\n",
       "      <td>car</td>\n",
       "      <td>quiz</td>\n",
       "      <td>tour</td>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ft</td>\n",
       "      <td>transfer</td>\n",
       "      <td>premier</td>\n",
       "      <td>world</td>\n",
       "      <td>2021</td>\n",
       "      <td>virtual</td>\n",
       "      <td>year</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>little</td>\n",
       "      <td>united</td>\n",
       "      <td>city</td>\n",
       "      <td>cup</td>\n",
       "      <td>results</td>\n",
       "      <td>pub</td>\n",
       "      <td>van</td>\n",
       "      <td>baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000</td>\n",
       "      <td>goldbridge</td>\n",
       "      <td>united</td>\n",
       "      <td>week</td>\n",
       "      <td>national</td>\n",
       "      <td>la</td>\n",
       "      <td>home</td>\n",
       "      <td>reveal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tour</td>\n",
       "      <td>manchester</td>\n",
       "      <td>arsenal</td>\n",
       "      <td>game</td>\n",
       "      <td>draw</td>\n",
       "      <td>date</td>\n",
       "      <td>moving</td>\n",
       "      <td>nba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>announcement</td>\n",
       "      <td>reaction</td>\n",
       "      <td>chelsea</td>\n",
       "      <td>nfl</td>\n",
       "      <td>lottery</td>\n",
       "      <td>day</td>\n",
       "      <td>tom</td>\n",
       "      <td>build</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Topic0      Topic1      Topic2      Topic3    Topic4   Topic5  \\\n",
       "0       trailer         man  highlights        2020       new     live   \n",
       "1      official        news      league  highlights    update     2021   \n",
       "2        season         utd          vs          vs       car     quiz   \n",
       "3            ft    transfer     premier       world      2021  virtual   \n",
       "4        little      united        city         cup   results      pub   \n",
       "5           000  goldbridge      united        week  national       la   \n",
       "6          tour  manchester     arsenal        game      draw     date   \n",
       "7  announcement    reaction     chelsea         nfl   lottery      day   \n",
       "\n",
       "   Topic6  Topic7  \n",
       "0   house    best  \n",
       "1     new     day  \n",
       "2    tour    life  \n",
       "3    year    2020  \n",
       "4     van    baby  \n",
       "5    home  reveal  \n",
       "6  moving     nba  \n",
       "7     tom   build  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "below_table = create_findings_table(remaining_topics_below)\n",
    "below_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Topic7</th>\n",
       "      <th>Topic8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>minecraft</td>\n",
       "      <td>000</td>\n",
       "      <td>shorts</td>\n",
       "      <td>trailer</td>\n",
       "      <td>night</td>\n",
       "      <td>video</td>\n",
       "      <td>game</td>\n",
       "      <td>mv</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>en</td>\n",
       "      <td>fortnite</td>\n",
       "      <td>official</td>\n",
       "      <td>friday</td>\n",
       "      <td>official</td>\n",
       "      <td>2021</td>\n",
       "      <td>teaser</td>\n",
       "      <td>got</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>days</td>\n",
       "      <td>le</td>\n",
       "      <td>tiktok</td>\n",
       "      <td>theory</td>\n",
       "      <td>funkin</td>\n",
       "      <td>music</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vs</td>\n",
       "      <td>les</td>\n",
       "      <td>season</td>\n",
       "      <td>film</td>\n",
       "      <td>mod</td>\n",
       "      <td>ft</td>\n",
       "      <td>highlights</td>\n",
       "      <td>bad</td>\n",
       "      <td>season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>challenge</td>\n",
       "      <td>vs</td>\n",
       "      <td>reveal</td>\n",
       "      <td>live</td>\n",
       "      <td>feat</td>\n",
       "      <td>bts</td>\n",
       "      <td>boss</td>\n",
       "      <td>war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>man</td>\n",
       "      <td>wins</td>\n",
       "      <td>new</td>\n",
       "      <td>food</td>\n",
       "      <td>hot</td>\n",
       "      <td>lil</td>\n",
       "      <td>life</td>\n",
       "      <td>try</td>\n",
       "      <td>unboxing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dream</td>\n",
       "      <td>la</td>\n",
       "      <td>challenge</td>\n",
       "      <td>teaser</td>\n",
       "      <td>tour</td>\n",
       "      <td>audio</td>\n",
       "      <td>squid</td>\n",
       "      <td>2021</td>\n",
       "      <td>snl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>paul</td>\n",
       "      <td>ft</td>\n",
       "      <td>hacks</td>\n",
       "      <td>don</td>\n",
       "      <td>animation</td>\n",
       "      <td>oficial</td>\n",
       "      <td>clip</td>\n",
       "      <td>movie</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic0     Topic1     Topic2    Topic3     Topic4    Topic5      Topic6  \\\n",
       "0  minecraft        000     shorts   trailer      night     video        game   \n",
       "1        100         en   fortnite  official     friday  official        2021   \n",
       "2       days         le     tiktok    theory     funkin     music        2020   \n",
       "3         vs        les     season      film        mod        ft  highlights   \n",
       "4         24  challenge         vs    reveal       live      feat         bts   \n",
       "5        man       wins        new      food        hot       lil        life   \n",
       "6      dream         la  challenge    teaser       tour     audio       squid   \n",
       "7       paul         ft      hacks       don  animation   oficial        clip   \n",
       "\n",
       "   Topic7    Topic8  \n",
       "0      mv      free  \n",
       "1  teaser       got  \n",
       "2    2020    people  \n",
       "3     bad    season  \n",
       "4    boss       war  \n",
       "5     try  unboxing  \n",
       "6    2021       snl  \n",
       "7   movie      cold  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "above_table = create_findings_table(remaining_topics_above)\n",
    "above_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "above_list = above_table.values.flatten().tolist()\n",
    "below_list = below_table.values.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib_venn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Venn Diagram\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib_venn\u001b[39;00m \u001b[39mimport\u001b[39;00m venn2\n\u001b[1;32m      5\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m4\u001b[39m,\u001b[39m4\u001b[39m))\n\u001b[1;32m      6\u001b[0m set1 \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(above_list)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib_venn'"
     ]
    }
   ],
   "source": [
    "#Venn Diagram\n",
    "from matplotlib_venn import venn2\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "set1 = set(above_list)\n",
    "set2 = set(below_list)\n",
    "\n",
    "venn2([set1, set2], ('Set1', 'Set2'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib_venn_wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib_venn_wordcloud\u001b[39;00m \u001b[39mimport\u001b[39;00m venn2_wordcloud\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib_venn_wordcloud'"
     ]
    }
   ],
   "source": [
    "from matplotlib_venn_wordcloud import venn2_wordcloud\n",
    "#https://github.com/paulbrodersen/matplotlib_venn_wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topical_coherence(test_list, w2vmodel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Title+Description in All_Text\n",
    "[0.43928024, 0.44796124, 0.45181724, 0.44953543, 0.44237196, 0.46059352, 0.45885643, 0.43762824, 0.4357811, 0.42841437, 0.4201536, 0.42084923, 0.42975327, 0.4204068, 0.41796622, 0.40867746, 0.4156867, 0.41626924, 0.41916725]\n",
    "The values for the best average coherence model are\n",
    "{0: ['com', 'https', 'http', 'ly', 'www', 'bit', 'instagram', 'twitter'], 1: ['https', 'com', 'www', 'twitter', 'instagram', 'youtube', 'http', 'facebook'], 2: ['https', 'com', 'www', 'youtube', 'instagram', 'twitter', 'channel', 'http'], 3: ['https', 'und', 'die', 'com', 'www', 'auf', 'der', 'http'], 4: ['com', 'https', 'que', 'da', 'like', 'official', 'se', 'www'], 5: ['https', 'amzn', 'ly', 'bit', 'la', 'et', 'le', 'les']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.3125137\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "max_index = np.argmax(results)\n",
    "print(max_index)\n",
    "print(results[max_index])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0.43928024, 0.44796124, 0.45181724, 0.44953543, 0.44237196, 0.46059352, 0.45885643, 0.43762824, 0.4357811, 0.42841437, 0.4201536, 0.42084923, 0.42975327, 0.4204068, 0.41796622, 0.40867746, 0.4156867, 0.41626924, 0.41916725]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29e8d7c574c1c3fa7d750bb72c4ea3c797abd9d323046819b3334e09977e0d16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
