import pandas as pd
import numpy as np
import json

import gensim
import gensim.corpora as corpora
from gensim.utils import simple_preprocess
import pyLDAvis
import pyLDAvis.gensim
from gensim.models import LdaModel


video_df = pd.read_csv('../../../data/video_transcripts_mix_clean.csv')


video_df.head(3)





video_df['clean_combined'] = video_df[['title_Clean','tags_Clean','description_Clean','Transcript_Blob_Clean']].apply( lambda x: ' '.join(x.dropna()), axis=1)


video_df.loc[:,video_df.columns.str.contains('clean', case=False)].head(3)


tokenized_vid = [vid.split() for vid in video_df['clean_combined'].tolist()]

id2word = corpora.Dictionary(tokenized_vid)
corpus = [id2word.doc2bow(tokens) for tokens in tokenized_vid]


corpus_sample = corpus[1][0:5]
print(corpus_sample)

print(id2word[[0][:1][0]])



lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,
                                            id2word=id2word,
                                            num_topics=50, 
                                            random_state=42,
                                            update_every=1,
                                            chunksize=10000,
                                            passes=10,
                                            alpha='auto', 
                                            eta='auto',
                                            eval_every=None)


lda_model.save('../../../data/lda_all_combined_50T.model')


lda_model = LdaModel.load('../../../models/lda_all_combined_50T.model')


pyLDAvis.enable_notebook()
vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, mds='mmds', R=50 )
vis


lda_model.show_topics(topics=-1, topn=10)
